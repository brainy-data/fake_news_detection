{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Fake_news_detection.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "euXvCsvYifGp"
      ],
      "authorship_tag": "ABX9TyNXXeXGSnZwbt2a3xxhgP74",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/brainy-data/fake_news_detection/blob/main/deployment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euXvCsvYifGp"
      },
      "source": [
        "# Set-up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OjVxbVbw6j4n"
      },
      "source": [
        "#Library required\n",
        "%%capture\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import re\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('words')\n",
        "wordnet_lemmatizer = WordNetLemmatizer()"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7RR3bKjcMiz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2140a27f-0d14-4b1c-ba3b-4f5c18d422b0"
      },
      "source": [
        "#Import trained model from google drive\n",
        "!gdown --id 12v6MzTMFmQrEg85pSN2tHCZBpX8JY67h\n",
        "!gdown --id 1Ux1ecLbHBZZK132ZYY3nWnI1YdUAKFWc"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=12v6MzTMFmQrEg85pSN2tHCZBpX8JY67h\n",
            "To: /content/fake_lgb_model.pickle\n",
            "100% 218k/218k [00:00<00:00, 32.5MB/s]\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1Ux1ecLbHBZZK132ZYY3nWnI1YdUAKFWc\n",
            "To: /content/fake_tfidf.pickle\n",
            "101MB [00:00, 163MB/s] \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1OAMW7rFe_7Z"
      },
      "source": [
        "#load the model trained above\n",
        "loaded_tfidf = pickle.load(open(\"fake_tfidf.pickle\", \"rb\"))\n",
        "loaded_lgb_model = pickle.load(open(\"fake_lgb_model.pickle\", \"rb\"))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WnZhY5MJ624L"
      },
      "source": [
        "#Function for text pre-processing\n",
        "def get_cleaned_data(input_data, mode='df'):\n",
        "    stop = stopwords.words('english')\n",
        "    input_df = ''\n",
        "    if mode != 'df':\n",
        "        input_df = pd.DataFrame([input_data], columns=['text'])\n",
        "    else:\n",
        "        input_df = input_data       \n",
        "    #lowercase the text\n",
        "    input_df['text'] = input_df['text'].str.lower()    \n",
        "    #remove special characters\n",
        "    input_df['text'] = input_df['text'].apply(lambda elem: re.sub(r\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)|^rt|http.+?\", \"\", elem))    \n",
        "    # remove numbers\n",
        "    input_df['text'] = input_df['text'].apply(lambda elem: re.sub(r\"\\d+\", \"\", elem))    \n",
        "    #remove stopwords\n",
        "    input_df['text'] = input_df['text'].apply(lambda x: ' '.join([word.strip() for word in x.split() if word not in (stop)]))\n",
        "    input_df['text'] = input_df['text'].apply(lambda words: (wordnet_lemmatizer.lemmatize(words)))\n",
        "    return input_df"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZUPCaK7fm2U"
      },
      "source": [
        "# define function for prediction\n",
        "def predict(text):\n",
        "  review_text = text\n",
        "  cleaned_text= get_cleaned_data(review_text,mode=\"non-df\")\n",
        "  new_test = loaded_tfidf.transform(cleaned_text['text'])\n",
        "  pred_prob = loaded_lgb_model.predict_proba(new_test)\n",
        "  if pred_prob[0][1] >=0.5:\n",
        "    print('{:.2%} that it is fake'.format(pred_prob[0][1]))\n",
        "  else:\n",
        "    print('{:.2%} that it is real'.format(pred_prob[0][0]))"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUVnb_-fhneM"
      },
      "source": [
        "# Examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Bp3w9aTgllZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74cab284-af81-4b45-f903-e2ccac800f12"
      },
      "source": [
        "# fake_news_testing (from random sentence generator)\n",
        "# may need to remove ' or \" at first to avoid bug\n",
        "# Source: https://edition.cnn.com/2021/04/20/health/blood-clots-experts-covid-vaccine/index.html\n",
        "text = ['Her scream silenced the rowdy teenagers. Traveling became almost extinct during the pandemic. She lived on Monkey Jungle Road and that seemed to explain all of her strangeness. Facing his greatest fear, he ate his first marshmallow. Sometimes, all you need to do is completely make an ass of yourself and laugh it off to realise that life isnâ€™t so bad after all. They say that dogs are mans best friend, but this cat was setting out to sabotage that theory. Today is the day I will finally know what brick tastes like. They were excited to see their first sloth.']\n",
        "predict(text)"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94.52% that it is fake\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dRd1QQcegnyK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd2ed81f-a560-4916-82ed-44106d9574c3"
      },
      "source": [
        "# real_nbews_testing\n",
        "# may need to remove ' or \" at first to avoid bug\n",
        "# Source: https://edition.cnn.com/2021/04/20/health/blood-clots-experts-covid-vaccine/index.html\n",
        "text = ['It was just about a year ago that doctors started noticing Covid-19 patients showing up in emergency rooms with strokes, and complained that blood clots were clogging up dialysis machines and other equipment being used to keep coronavirus patients alive.Frantic intensive care unit specialists reported \"dramatic\" blood clots in the heart, liver and other organs. Autopsies of coronavirus victims in New Orleans showed their lungs were jammed with clots. Some young, seemingly healthy patients were suffering massive strokes from Covid-19. As a blood clot expert, I can tell you its the most blood-clotting disease we have ever seen in our lifetimes,\" said Dr. Alex Spyropoulos, a professor at the Feinstein Institutes for Medical Research in New York.\" I have been doing this for a quarter century. I have never seen these levels of blood clots.\"']\n",
        "predict(text)"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "75.50% that it is real\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfwTM_kPiLci"
      },
      "source": [
        "# Run all cells (Ctrl+F9) and then call the function predict with your text / article\n",
        "# paste your article into variable text\n",
        "# predict(\"your_text\")"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjDk2s0VmdVK"
      },
      "source": [
        "text = [\"\"]\n",
        "predict(text)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}